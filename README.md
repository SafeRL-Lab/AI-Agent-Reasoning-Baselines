# AI-Agent-Reasoning-Papers

1. [The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity](https://arxiv.org/pdf/2506.06941) *(June 7, 2025)* 
2. [Just Enough Thinking: Efficient Reasoning with Adaptive Length Penalties Reinforcement Learning](http://arxiv.org/abs/2506.05256) *(June 2025)*  
3. [Does Thinking More always Help? Understanding Test‑Time Scaling in Reasoning Models](http://arxiv.org/abs/2506.04210) *(June 2025)*  
4. [The Illusion of Thinking: Comment on Shojaee et al.](https://arxiv.org/abs/2506.09250) *(June 10, 2025)* 
5. [WorkForceAgent‑R1: Incentivizing Reasoning Capability in LLM-based Web Agents via Reinforcement Learning](http://arxiv.org/abs/2505.22942) *(May 22, 2025)*  
6. [Learning When to Think: Shaping Adaptive Reasoning in R1‑Style Models via Multi‑Stage RL](https://arxiv.org/pdf/2505.10832) *(May 16, 2025)*
7. [AdaptThink: Reasoning Models Can Learn When to Think](https://arxiv.org/abs/2505.13417) *(May 19, 2025)*  
8. [Chain‑of‑Thought Tokens are Computer Program Variables](http://arxiv.org/abs/2505.04955) *(May 2025)*  
9. [Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?](http://arxiv.org/abs/2504.13837) *(April 2025)*  
10. [Inference‑Time Scaling for Generalist Reward Modeling](http://arxiv.org/abs/2504.02495) *(April 2025)*  
11. [Test‑Time Reasoning Through Visual Human Preferences with VLMs and Soft Rewards](http://arxiv.org/abs/2503.19948) *(March 2025)*  
12. [SimpleRL‑Zoo: Investigating and Taming Zero Reinforcement Learning for Open Base Models in the Wild](http://arxiv.org/abs/2503.18892) *(March 2025)*  
13. [What Makes a Reward Model a Good Teacher? An Optimization Perspective](http://arxiv.org/abs/2503.15477) *(March 2025)*  
14. [Sketch‑of‑Thought: Efficient LLM Reasoning with Adaptive Cognitive‑Inspired Sketching](http://arxiv.org/abs/2503.05179) *(March 2025)*  
15. [All Roads Lead to Likelihood: The Value of Reinforcement Learning in Fine‑Tuning](http://arxiv.org/abs/2503.01067) *(March 2025)*  
16. [Reward Shaping to Mitigate Reward Hacking in RLHF](http://arxiv.org/abs/2502.18770) *(February 2025)*  
17. [Chain of Draft: Thinking Faster by Writing Less](http://arxiv.org/abs/2502.18600) *(February 2025)*  
18. [ReasonFlux: Hierarchical LLM Reasoning via Scaling Thought Templates](http://arxiv.org/abs/2502.06772) *(February 2025)*  
19. [Step Back to Leap Forward: Self‑Backtracking for Boosting Reasoning of Language Models](http://arxiv.org/abs/2502.04404) *(February 2025)*  
20. [SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post‑training](http://arxiv.org/abs/2501.17161) *(January 2025)*  
21. [Think Smarter not Harder: Adaptive Reasoning with Inference Aware Optimization](http://arxiv.org/abs/2501.17974) *(January 2025)*  
22. [LLMs Can Plan Only If We Tell Them](http://arxiv.org/abs/2501.13545) *(January 2025)*  
23. [Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain‑of‑Thought](http://arxiv.org/abs/2501.04682) *(January 2025)*  
24. [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](http://arxiv.org/abs/2305.10601) *(May 2023)*  
25. [Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language Models](http://arxiv.org/abs/2308.10379) *(August 2023)*  
26. [Automatic Curriculum Expert Iteration for Reliable LLM Reasoning](http://arxiv.org/abs/2410.07627) *(October 2024)*  
27. [Can LLMs Learn by Teaching for Better Reasoning? A Preliminary Study](http://arxiv.org/abs/2406.14629) *(June 2024)*  
28. [Quiet‑STaR: Language Models Can Teach Themselves to Think Before Speaking](http://arxiv.org/abs/2403.09629) *(March 2024)*  
29. [Combinatorial Reasoning: Selecting Reasons in Generative AI Pipelines via Combinatorial Optimization](http://arxiv.org/abs/2407.00071) *(July 2024)*  
30. [Self‑Rewarding Language Models](http://arxiv.org/abs/2401.10020) *(January 2024)*  
31. [The Impact of Reasoning Step Length on Large Language Models](http://arxiv.org/abs/2401.04925) *(January 2024)*  
32. [STaR: Bootstrapping Reasoning With Reasoning](http://arxiv.org/abs/2203.14465) *(March 2022)*  
33. [Self‑Consistency Improves Chain of Thought Reasoning in Language Models](http://arxiv.org/abs/2203.11171) *(March 2022)*  
