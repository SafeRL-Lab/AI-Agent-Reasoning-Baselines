# AI-Agent-Reasoning-Papers
## Reasoning Paper List

### 2025
- AceReason-Nemotron 1.1: Advancing Math and Code Reasoning through SFT and RL Synergy, [Paper](https://arxiv.org/pdf/2506.13284) *(Jun 13, 2025)*
- Spurious Rewards: Rethinking Training Signals in RLVR, [Paper](https://arxiv.org/pdf/2506.10947) *(Jun 12, 2025)*
- RSVP: Reasoning Segmentation via Visual Prompting and Multi-modal Chain-of-Thought, [Paper](https://arxiv.org/abs/2506.04277) *(June 4, 2025)*  
- The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity, [Paper](https://arxiv.org/pdf/2506.06941) *(June 7, 2025)*  
- Just Enough Thinking: Efficient Reasoning with Adaptive Length Penalties Reinforcement Learning, [Paper](http://arxiv.org/abs/2506.05256) *(June 2025)*  
- Does Thinking More always Help? Understanding Test‑Time Scaling in Reasoning Models, [Paper](http://arxiv.org/abs/2506.04210) *(June 2025)*  
- The Illusion of Thinking: Comment on Shojaee et al., [Paper](https://arxiv.org/abs/2506.09250) *(June 10, 2025)*
- ReMA: Learning to Meta-think for LLMs with Multi-agent Reinforcement Learning, [Paper](https://arxiv.org/pdf/2503.09501) *(May 27, 2025)*
- WorkForceAgent‑R1: Incentivizing Reasoning Capability in LLM-based Web Agents via Reinforcement Learning, [Paper](http://arxiv.org/abs/2505.22942) *(May 22, 2025)*  
- AdaptThink: Reasoning Models Can Learn When to Think, [Paper](https://arxiv.org/abs/2505.13417) *(May 19, 2025)*  
- Learning When to Think: Shaping Adaptive Reasoning in R1‑Style Models via Multi‑Stage RL, [Paper](https://arxiv.org/pdf/2505.10832) *(May 16, 2025)*
- Llama-Nemotron: Efficient Reasoning Models, [Paper](https://arxiv.org/pdf/2505.00949) *(May 15, 2025)*
- Chain‑of‑Thought Tokens are Computer Program Variables, [Paper](http://arxiv.org/abs/2505.04955) *(May 2025)*  
- SegEarth-R1: Geospatial Pixel Reasoning via Large Language Model, [Paper](https://arxiv.org/abs/2504.09644) *(April 13, 2025)* 
- Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?, [Paper](http://arxiv.org/abs/2504.13837) *(April 18, 2025)*
- Climbing the Ladder of Reasoning: What LLMs Can—and Still Can’t—Solve after SFT?, [Paper](http://arxiv.org/abs/2504.11741) *(April 16, 2025)*  
- Inference‑Time Scaling for Generalist Reward Modeling, [Paper](http://arxiv.org/abs/2504.02495) *(April 3, 2025)*  
- Test‑Time Reasoning Through Visual Human Preferences with VLMs and Soft Rewards, [Paper](http://arxiv.org/abs/2503.19948) *(March 2025)*  
- SimpleRL‑Zoo: Investigating and Taming Zero Reinforcement Learning for Open Base Models in the Wild, [Paper](http://arxiv.org/abs/2503.18892) *(March 2025)*  
- What Makes a Reward Model a Good Teacher? An Optimization Perspective, [Paper](http://arxiv.org/abs/2503.15477) *(March 2025)*  
- Sketch‑of‑Thought: Efficient LLM Reasoning with Adaptive Cognitive‑Inspired Sketching, [Paper](http://arxiv.org/abs/2503.05179) *(March 2025)*  
- All Roads Lead to Likelihood: The Value of Reinforcement Learning in Fine‑Tuning, [Paper](http://arxiv.org/abs/2503.01067) *(March 2025)*  
- Reward Shaping to Mitigate Reward Hacking in RLHF, [Paper](http://arxiv.org/abs/2502.18770) *(February 2025)*
- Reward-Guided Speculative Decoding for Efficient LLM Reasoning, [Paper](https://arxiv.org/pdf/2501.19324), *(Feb 14, 2025)*
- Chain of Draft: Thinking Faster by Writing Less, [Paper](http://arxiv.org/abs/2502.18600) *(February 2025)*  
- ReasonFlux: Hierarchical LLM Reasoning via Scaling Thought Templates, [Paper](http://arxiv.org/abs/2502.06772) *(February 2025)*  
- Step Back to Leap Forward: Self‑Backtracking for Boosting Reasoning of Language Models, [Paper](http://arxiv.org/abs/2502.04404) *(February 2025)*  
- SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post‑training, [Paper](http://arxiv.org/abs/2501.17161) *(January 2025)*  
- Think Smarter not Harder: Adaptive Reasoning with Inference Aware Optimization, [Paper](http://arxiv.org/abs/2501.17974) *(January 2025)*  
- LLMs Can Plan Only If We Tell Them, [Paper](http://arxiv.org/abs/2501.13545) *(January 2025)*  
- Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain‑of‑Thought, [Paper](http://arxiv.org/abs/2501.04682) *(January 2025)*

### 2024
- SegLLM: Multi-round Reasoning Segmentation, [Paper](https://arxiv.org/abs/2410.18923) *(October 24, 2024)* 
- Automatic Curriculum Expert Iteration for Reliable LLM Reasoning, [Paper](http://arxiv.org/abs/2410.07627) *(October 2024)*  
- Combinatorial Reasoning: Selecting Reasons in Generative AI Pipelines via Combinatorial Optimization, [Paper](http://arxiv.org/abs/2407.00071) *(July 2024)*
- RouteLLM: Learning to Route LLMs with Preference Data, [Paper](https://arxiv.org/pdf/2406.18665), *(Jun 26, 2024)*
- Can LLMs Learn by Teaching for Better Reasoning? A Preliminary Study, [Paper](http://arxiv.org/abs/2406.14629) *(June 2024)*  
- Quiet‑STaR: Language Models Can Teach Themselves to Think Before Speaking, [Paper](http://arxiv.org/abs/2403.09629) *(March 2024)*  
- Self‑Rewarding Language Models, [Paper](http://arxiv.org/abs/2401.10020) *(January 2024)*  
- The Impact of Reasoning Step Length on Large Language Models, [Paper](http://arxiv.org/abs/2401.04925) *(January 2024)*

### 2023
- Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language Models, [Paper](http://arxiv.org/abs/2308.10379) *(August 2023)*  
- Tree of Thoughts: Deliberate Problem Solving with Large Language Models, [Paper](http://arxiv.org/abs/2305.10601) *(May 2023)*

### 2022
- STaR: Bootstrapping Reasoning With Reasoning, [Paper](http://arxiv.org/abs/2203.14465) *(March 2022)*  
- Self‑Consistency Improves Chain of Thought Reasoning in Language Models, [Paper](http://arxiv.org/abs/2203.11171) *(March 2022)*  
